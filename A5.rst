.. code:: ipython3

    import os
    import shutil
    import tensorflow as tf
    import numpy as np
    import matplotlib.pyplot as plt
    from tensorflow.keras.preprocessing import image as image_utils
    from tensorflow.keras.applications.densenet import preprocess_input
    from tensorflow.keras.utils import image_dataset_from_directory
    from tensorflow.keras.applications import DenseNet121
    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
    from tensorflow.keras.models import Model
    from sklearn.metrics import confusion_matrix, roc_curve, auc
    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
    from PIL import ImageFile
    from tensorflow.keras.utils import Sequence
    import numpy as np
    from keras.callbacks import Callback
    import sys

.. code:: ipython3

    # Define constants for data management and training
    resized_height = 224
    resized_width = 224
    num_channel = 3
    num_classes = 14
    batch_size = 128
    
    # Define the list of disease classes
    disease_classes = [
        'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',
        'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',
        'No_Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'
    ]
    
    # Paths for the source directory and the destination directory
    source_dir = '/blue/bsc4892/share/ChestXray-NIHCC/images_Pneumonia_labeled_subset'
    dest_dir = '/blue/bsc4892/jknight/Assignment_5/balanced_images_15_cat/'
    
    # Create destination directories for each disease class
    for disease in disease_classes:
        os.makedirs(os.path.join(dest_dir, disease), exist_ok=True)
    
    # Loop through each file in the source directory
    for filename in os.listdir(source_dir):
        # Check if the file is an image
        if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):
            # Determine the disease class from the filename
            for disease in disease_classes:
                if disease in filename:
                    shutil.move(os.path.join(source_dir, filename), os.path.join(dest_dir, disease))
                    break


.. code:: ipython3

    # Set to load truncated images, if any
    ImageFile.LOAD_TRUNCATED_IMAGES = True
    
    # Initialize your data generators
    train_datagen = ImageDataGenerator(
        preprocessing_function=preprocess_input,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    test_val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
    
    class BalancedDataGenerator(Sequence):
        def __init__(self, directory, image_data_generator, target_size=(224, 224), batch_size=32, shuffle=True, seed=None):
            self.directory = directory
            self.image_data_generator = image_data_generator
            self.target_size = target_size
            self.batch_size = batch_size
            self.shuffle = shuffle
            self.generator = image_data_generator.flow_from_directory(
                directory,
                target_size=target_size,
                class_mode='categorical',
                batch_size=1,  # We handle batching manually
                shuffle=False,
                seed=seed)
            self.num_classes = len(self.generator.class_indices)
            self.class_indices = [np.where(self.generator.classes == i)[0] for i in range(self.num_classes)]
            self.image_shape = (target_size[0], target_size[1], 3)  # assuming RGB images
    
        def __len__(self):
            return int(np.floor(min([len(indices) for indices in self.class_indices]) * self.num_classes / self.batch_size))
    
        def on_epoch_end(self):
            if self.shuffle:
                for indices in self.class_indices:
                    np.random.shuffle(indices)
    
        def __getitem__(self, idx):
            batch_x = np.zeros((self.batch_size,) + self.image_shape, dtype='float32')
            batch_y = np.zeros((self.batch_size, self.num_classes), dtype='float32')
            
            num_samples_per_class = self.batch_size // self.num_classes
            extra_samples = self.batch_size % self.num_classes
    
            class_cycle = np.arange(self.num_classes)
            np.random.shuffle(class_cycle)
    
            batch_indices = []
            for class_idx in class_cycle:
                class_samples = num_samples_per_class + (1 if extra_samples > 0 else 0)
                batch_indices.extend(np.random.choice(self.class_indices[class_idx], class_samples, replace=False))
                extra_samples -= 1
    
            for i, img_idx in enumerate(batch_indices):
                img_path = self.generator.filepaths[img_idx]
                img = load_img(img_path, target_size=self.target_size)
                x = img_to_array(img)
                x = preprocess_input(x)
                batch_x[i] = x
                batch_y[i] = self.generator.classes[img_idx]
    
            return batch_x, batch_y

.. code:: ipython3

    # Create instances of BalancedDataGenerator
    train_generator = BalancedDataGenerator(
        'balanced_images/train',
        train_datagen,
        batch_size=32
    )
    
    validation_generator = BalancedDataGenerator(
        'balanced_images_15_cat/val',
        test_val_datagen,
        batch_size=32
    )
    
    # Standard generator for testing (balance not typically required)
    test_generator = test_val_datagen.flow_from_directory(
        'balanced_images_15_cat/test',
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )


::


    ---------------------------------------------------------------------------

    FileNotFoundError                         Traceback (most recent call last)

    Input In [52], in <cell line: 2>()
          1 # Create instances of BalancedDataGenerator
    ----> 2 train_generator = BalancedDataGenerator(
          3     'balanced_images/train',
          4     train_datagen,
          5     batch_size=32
          6 )
          8 validation_generator = BalancedDataGenerator(
          9     'balanced_images_15_cat/val',
         10     test_val_datagen,
         11     batch_size=32
         12 )
         14 # Standard generator for testing (balance not typically required)


    Input In [51], in BalancedDataGenerator.__init__(self, directory, image_data_generator, target_size, batch_size, shuffle, seed)
         23 self.batch_size = batch_size
         24 self.shuffle = shuffle
    ---> 25 self.generator = image_data_generator.flow_from_directory(
         26     directory,
         27     target_size=target_size,
         28     class_mode='categorical',
         29     batch_size=1,  # We handle batching manually
         30     shuffle=False,
         31     seed=seed)
         32 self.num_classes = len(self.generator.class_indices)
         33 self.class_indices = [np.where(self.generator.classes == i)[0] for i in range(self.num_classes)]


    File /apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/preprocessing/image.py:976, in ImageDataGenerator.flow_from_directory(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)
        898 def flow_from_directory(self,
        899                         directory,
        900                         target_size=(256, 256),
       (...)
        911                         subset=None,
        912                         interpolation='nearest'):
        913   """Takes the path to a directory & generates batches of augmented data.
        914 
        915   Args:
       (...)
        974           and `y` is a numpy array of corresponding labels.
        975   """
    --> 976   return DirectoryIterator(
        977       directory,
        978       self,
        979       target_size=target_size,
        980       color_mode=color_mode,
        981       classes=classes,
        982       class_mode=class_mode,
        983       data_format=self.data_format,
        984       batch_size=batch_size,
        985       shuffle=shuffle,
        986       seed=seed,
        987       save_to_dir=save_to_dir,
        988       save_prefix=save_prefix,
        989       save_format=save_format,
        990       follow_links=follow_links,
        991       subset=subset,
        992       interpolation=interpolation)


    File /apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/preprocessing/image.py:394, in DirectoryIterator.__init__(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)
        392     dtype = backend.floatx()
        393   kwargs['dtype'] = dtype
    --> 394 super(DirectoryIterator, self).__init__(
        395     directory, image_data_generator,
        396     target_size=target_size,
        397     color_mode=color_mode,
        398     classes=classes,
        399     class_mode=class_mode,
        400     batch_size=batch_size,
        401     shuffle=shuffle,
        402     seed=seed,
        403     data_format=data_format,
        404     save_to_dir=save_to_dir,
        405     save_prefix=save_prefix,
        406     save_format=save_format,
        407     follow_links=follow_links,
        408     subset=subset,
        409     interpolation=interpolation,
        410     **kwargs)


    File /apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras_preprocessing/image/directory_iterator.py:115, in DirectoryIterator.__init__(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)
        113 if not classes:
        114     classes = []
    --> 115     for subdir in sorted(os.listdir(directory)):
        116         if os.path.isdir(os.path.join(directory, subdir)):
        117             classes.append(subdir)


    FileNotFoundError: [Errno 2] No such file or directory: 'balanced_images/train'


.. code:: ipython3

    base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(15, activation='softmax')(x)
    
    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    history = model.fit(
        train_generator,
        steps_per_epoch=7,  # Adjust based on the size of your dataset
        epochs=8,  # Adjust based on your early experiments
        validation_data=validation_generator,
        validation_steps=10  # Adjust based on the size of your validation set
    )


.. parsed-literal::

    Epoch 1/8
    7/7 [==============================] - 65s 8s/step - loss: 396.4232 - accuracy: 0.0089 - val_loss: 898.3729 - val_accuracy: 0.0000e+00
    Epoch 2/8
    7/7 [==============================] - 52s 8s/step - loss: 878.3668 - accuracy: 0.0000e+00 - val_loss: 3230.3640 - val_accuracy: 0.0000e+00
    Epoch 3/8
    7/7 [==============================] - 53s 8s/step - loss: 1465.2429 - accuracy: 0.0000e+00 - val_loss: 5392.7666 - val_accuracy: 0.0000e+00
    Epoch 4/8
    7/7 [==============================] - 52s 8s/step - loss: 2093.7717 - accuracy: 0.0000e+00 - val_loss: 2455.5093 - val_accuracy: 0.0000e+00
    Epoch 5/8
    7/7 [==============================] - 53s 8s/step - loss: 2708.2722 - accuracy: 0.0000e+00 - val_loss: 1735.0339 - val_accuracy: 0.0000e+00
    Epoch 6/8
    7/7 [==============================] - 53s 8s/step - loss: 3537.9226 - accuracy: 0.0000e+00 - val_loss: 3042.3071 - val_accuracy: 0.0000e+00
    Epoch 7/8
    7/7 [==============================] - 52s 8s/step - loss: 4511.6924 - accuracy: 0.0000e+00 - val_loss: 4504.8975 - val_accuracy: 0.0000e+00
    Epoch 8/8
    7/7 [==============================] - 52s 8s/step - loss: 5439.8403 - accuracy: 0.0000e+00 - val_loss: 2962.8079 - val_accuracy: 0.0000e+00


.. code:: ipython3

    test_loss, test_acc = model.evaluate(test_generator, steps=50)  # Adjust the steps as needed
    print('Test accuracy:', test_acc)


.. parsed-literal::

    50/50 [==============================] - 55s 1s/step - loss: 13.8588 - accuracy: 0.0000e+00
    Test accuracy: 0.0


.. code:: ipython3

    # Summarize history for accuracy
    plt.figure(figsize=(8, 8))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Val'], loc='upper left')
    plt.show()
    
    # Summarize history for loss
    plt.figure(figsize=(8, 8))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Val'], loc='upper right')
    plt.show()




.. image:: output_6_0.png



.. image:: output_6_1.png


